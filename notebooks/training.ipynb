{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pickle, gzip, os\n",
    "from pathlib import Path\n",
    "from fastai import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(os.getcwd() + \"/dataset/mnist\")\n",
    "path = datasets.download_data(MNIST_URL, path, ext='.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(path, 'rb') as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = map(torch.tensor, (x_train, y_train, x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, m, s): return (x-m)/s\n",
    "\n",
    "def normalize_to(train, valid):\n",
    "    m, s = train.mean(), train.std()\n",
    "    return normalize(train, m, s), normalize(valid, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid = normalize_to(x_train, x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        \n",
    "    def forward(self, x): return self.func(x)\n",
    "    \n",
    "def flatten(x): return x.view(len(x), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_resize(x): return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model():\n",
    "    return nn.Sequential(\n",
    "        Lambda(mnist_resize),\n",
    "        nn.Conv2d( 1,  8, 5, 2, 2), nn.ReLU(),\n",
    "        nn.Conv2d( 8, 16, 3, 2, 1), nn.ReLU(),\n",
    "        nn.Conv2d(16, 32, 3, 2, 1), nn.ReLU(),\n",
    "        nn.Conv2d(32, 32, 3, 2, 1), nn.ReLU(),\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        Lambda(flatten),\n",
    "        nn.Linear(32, y_train.max().item() + 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, x, y): self.x, self.y = x, y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, i): return self.x[i], self.y[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "train_ds = Dataset(x_train, y_train)\n",
    "valid_ds = Dataset(x_valid, y_valid)\n",
    "\n",
    "train_dl = DataLoader(train_ds, bs, True)\n",
    "valid_dl = DataLoader(valid_ds, bs*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cnn_model()\n",
    "opt = optim.SGD(model.parameters(), .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_func(model(xb), yb).backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tot_loss, tot_acc = 0., 0.\n",
    "            for xb, yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                tot_loss += loss_func(pred, yb)\n",
    "                tot_acc  += accuracy (pred, yb)\n",
    "        nv = len(valid_dl)\n",
    "        print(\"epoch: {}  loss: {}  acc: {}\".format(e, tot_loss/nv, tot_acc/nv))\n",
    "    return tot_loss/nv, tot_acc/nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Below result comes from simple linear layers\n",
    "# nn.Sequential(nn.Linear(x_train.shape[-1], 50), nn.ReLU(), nn.Linear(50, 10))\n",
    "# saved in weight.pth\n",
    "\n",
    "# epoch: 0  loss: 0.10733925551176071  acc: 0.969936728477478\n",
    "# epoch: 1  loss: 0.09393870085477829  acc: 0.974782407283783\n",
    "# epoch: 2  loss: 0.11095812171697617  acc: 0.9709256291389465\n",
    "# epoch: 3  loss: 0.16840021312236786  acc: 0.9548061490058899"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.10532914102077484  acc: 0.9673655033111572\n",
      "epoch: 1  loss: 0.07269898802042007  acc: 0.9800237417221069\n",
      "epoch: 2  loss: 0.0744730532169342  acc: 0.9773536324501038\n",
      "epoch: 3  loss: 0.07222169637680054  acc: 0.9802215099334717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.0722), tensor(0.9802))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using CNN layers\n",
    "fit(4, model, F.cross_entropy, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"weight_cnn.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
